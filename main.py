import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
from collections import deque
import os
import chardet

# ê³µê°„ ë°ì´í„° ë° ê·¸ë˜í”„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import networkx as nx
import osmnx as ox
# âœ¨ geopy ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ âœ¨
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter # ìš”ì²­ ì œí•œì„ ìœ„í•œ ë„êµ¬

# Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic' # Windows ì‚¬ìš©ì
# plt.rcParams['font.family'] = 'AppleGothic' # macOS ì‚¬ìš©ì
plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€

st.set_page_config(page_title="ì‘ê¸‰ì˜ë£Œ ì´ì†¡ ë° ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸš‘ ì‘ê¸‰í™˜ì ì´ì†¡ ë° ì‘ê¸‰ì‹¤ ì´ìš© ë¶„ì„")

# -------------------------------
# íŒŒì¼ ê²½ë¡œ
# -------------------------------
transport_path = "data/ì •ë³´_01_í–‰ì •ì•ˆì „ë¶€_ì‘ê¸‰í™˜ìì´ì†¡ì—…(ê³µê³µë°ì´í„°í¬í„¸).csv"
time_json_path = "data/ì •ë³´_SOS_03.json"
month_json_path = "data/ì •ë³´_SOS_02.json"

# -------------------------------
# ë°ì´í„° ë¡œë”© í•¨ìˆ˜
# -------------------------------

# ... (load_transport_data í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€) ...
@st.cache_data
def load_transport_data(path):
    if not os.path.exists(path):
        st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()
    
    try:
        possible_encodings = ['cp949', 'euc-kr', 'utf-8', 'utf-8-sig'] 
        possible_seps = [',', ';', '\t', '|']

        df = None
        for enc in possible_encodings:
            for sep in possible_seps:
                try:
                    df = pd.read_csv(path, encoding=enc, sep=sep, on_bad_lines='skip', engine='python')
                    if not df.empty and len(df.columns) > 1:
                        st.info(f"'{path}' íŒŒì¼ì„ '{enc}' ì¸ì½”ë”©, êµ¬ë¶„ì '{sep}'ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                        return df
                    else:
                        continue 
                except (UnicodeDecodeError, pd.errors.ParserError) as e:
                    continue
                except Exception as e:
                    st.error(f"'{path}' íŒŒì¼ì„ ì—¬ëŠ” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (ì¸ì½”ë”©: {enc}, êµ¬ë¶„ì: {sep}): {e}")
                    continue
        
        st.error(f"'{path}' íŒŒì¼ì„ ì§€ì›ë˜ëŠ” ì–´ë–¤ ì¸ì½”ë”©/êµ¬ë¶„ìë¡œë„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()

    except Exception as e:
        st.error(f"'{path}' íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ìµœìƒìœ„ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# ... (load_time_data í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€) ...
@st.cache_data
def load_time_data(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            raw = json.load(f)
        records = raw[4:]
        time_cols = {
            'col5': '00-03ì‹œ', 'col6': '03-06ì‹œ', 'col7': '06-09ì‹œ', 'col8': '09-12ì‹œ',
            'col9': '12-15ì‹œ', 'col10': '15-18ì‹œ', 'col11': '18-21ì‹œ', 'col12': '21-24ì‹œ'
        }
        rows = []
        for row in records:
            region = row.get('col3')
            if region == "ì „ì²´" or not region:
                continue
            values = [int(row.get(c, "0").replace(",", "")) for c in time_cols.keys()]
            rows.append([region] + values)
        df = pd.DataFrame(rows, columns=['ì‹œë„'] + list(time_cols.values()))
        st.info(f"'{path}' JSON íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return df
    except FileNotFoundError:
        st.error(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()
    except json.JSONDecodeError as e:
        st.error(f"'{path}' JSON íŒŒì¼ ë””ì½”ë”© ì˜¤ë¥˜: {e}. íŒŒì¼ ë‚´ìš©ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"'{path}' JSON íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# ... (load_month_data í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€) ...
@st.cache_data
def load_month_data(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            raw = json.load(f)
        records = raw[4:]
        month_cols = {
            'col7': '1ì›”', 'col8': '2ì›”', 'col9': '3ì›”', 'col10': '4ì›”',
            'col11': '5ì›”', 'col12': '6ì›”', 'col13': '7ì›”', 'col14': '8ì›”',
            'col15': '9ì›”', 'col16': '10ì›”', 'col17': '11ì›”', 'col18': '12ì›”'
        }
        rows = []
        for row in records:
            region = row.get('col3')
            if region == "ì „ì²´" or not region:
                continue
            values = [int(row.get(c, "0").replace(",", "")) for c in month_cols.keys()]
            rows.append([region] + values)
        df = pd.DataFrame(rows, columns=['ì‹œë„'] + list(month_cols.values()))
        st.info(f"'{path}' JSON íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return df
    except FileNotFoundError:
        st.error(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()
    except json.JSONDecodeError as e:
        st.error(f"'{path}' JSON íŒŒì¼ ë””ì½”ë”© ì˜¤ë¥˜: {e}. íŒŒì¼ ë‚´ìš©ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"'{path}' JSON íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# osmnxë¥¼ ì‚¬ìš©í•˜ì—¬ ë„ë¡œë§ ê·¸ë˜í”„ë¥¼ ë¡œë“œí•˜ê³  networkx ê·¸ë˜í”„ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
@st.cache_data
def load_road_network_from_osmnx(place_name):
    try:
        st.info(f"'{place_name}' ì§€ì—­ì˜ ë„ë¡œë§ ë°ì´í„°ë¥¼ OpenStreetMapì—ì„œ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        G = ox.graph_from_place(place_name, network_type='drive', simplify=True, retain_all=True)
        st.success(f"'{place_name}' ë„ë¡œë§ì„ NetworkX ê·¸ë˜í”„ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤. ë…¸ë“œ ìˆ˜: {G.number_of_nodes()}, ê°„ì„  ìˆ˜: {G.number_of_edges()}")
        return G

    except Exception as e:
        st.error(f"'{place_name}' ë„ë¡œë§ ë°ì´í„°ë¥¼ OpenStreetMapì—ì„œ ê°€ì ¸ì˜¤ê³  ê·¸ë˜í”„ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.warning("ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜, ì§€ì—­ ì´ë¦„ì´ ì •í™•í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”. ë„ˆë¬´ í° ì§€ì—­ì„ ì§€ì •í•˜ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ë‚˜ íƒ€ì„ì•„ì›ƒì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return None

# âœ¨ Geopyë¥¼ ì´ìš©í•œ ì£¼ì†Œ ì§€ì˜¤ì½”ë”© í•¨ìˆ˜ âœ¨
@st.cache_data
def geocode_address(address, user_agent="emergency_app"):
    # Nominatim ì§€ì˜¤ì½”ë” ì´ˆê¸°í™”
    # user_agentëŠ” ì„œë¹„ìŠ¤ ì œê³µìì—ê²Œ ìì‹ ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹ë³„í•˜ëŠ” ìš©ë„ (í•„ìˆ˜)
    geolocator = Nominatim(user_agent=user_agent)
    
    # RateLimiterë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ì„ ë‘ì–´ ì„œë¹„ìŠ¤ ì œí•œ ë°©ì§€
    # Nominatimì€ ì´ˆë‹¹ 1íšŒ ìš”ì²­ ì œí•œ ê¶Œê³  (https://operations.osmfoundation.org/policies/nominatim/)
    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1) 

    try:
        if pd.isna(address) or not isinstance(address, str) or not address.strip():
            return None, None # ìœ íš¨í•˜ì§€ ì•Šì€ ì£¼ì†ŒëŠ” None ë°˜í™˜
        
        location = geocode(address)
        if location:
            return location.latitude, location.longitude
        else:
            return None, None
    except Exception as e:
        # st.warning(f"ì£¼ì†Œ '{address}' ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨: {e}") # ë””ë²„ê¹…ìš©ìœ¼ë¡œ í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
        return None, None

# -------------------------------
# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# -------------------------------
transport_df = load_transport_data(transport_path)

# --- âœ¨ transport_df ì „ì²˜ë¦¬: 'ì‹œë„ëª…' ì»¬ëŸ¼ ìƒì„± ë° ë³´ì • âœ¨ ---
if not transport_df.empty and 'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' in transport_df.columns:
    def extract_sido(address):
        if pd.isna(address):
            return None
        
        addr_str = str(address).strip() 
        if not addr_str: 
            return None

        parts = addr_str.split(' ')
        if not parts: 
            return None

        first_part = parts[0]

        if 'ì„¸ì¢…' in first_part:
            return 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ'
        
        korean_sido_list = ["ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°ê´‘ì—­ì‹œ", "ëŒ€êµ¬ê´‘ì—­ì‹œ", "ì¸ì²œê´‘ì—­ì‹œ", "ê´‘ì£¼ê´‘ì—­ì‹œ",
                                 "ëŒ€ì „ê´‘ì—­ì‹œ", "ìš¸ì‚°ê´‘ì—­ì‹œ", "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", "ê²½ê¸°ë„", "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
                                 "ì¶©ì²­ë¶ë„", "ì¶©ì²­ë‚¨ë„", "ì „ë¼ë¶ë„", "ì „ë¼ë‚¨ë„", "ê²½ìƒë¶ë„", "ê²½ìƒë‚¨ë„",
                                 "ì œì£¼íŠ¹ë³„ìì¹˜ë„"]
            
        for sido in korean_sido_list:
            if first_part in sido: 
                return sido 
        
        for part in parts:
            if isinstance(part, str) and ('íŠ¹ë³„ì‹œ' in part or 'ê´‘ì—­ì‹œ' in part or 'ìì¹˜ì‹œ' in part or 'ìì¹˜ë„' in part):
                if 'ê°•ì›' in part or 'ì „ë¼' in part or 'ì¶©ì²­' in part or 'ê²½ìƒ' in part or 'ê²½ê¸°' in part or 'ì œì£¼' in part:
                    if len(parts) > 1:
                        return f"{parts[0]}{part}"
                    else:
                        return part
                return part

        return None 

    transport_df['ì‹œë„ëª…'] = transport_df['ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ'].apply(extract_sido)

    # âœ¨ ìƒˆë¡œìš´ ì „ì²˜ë¦¬: 'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ'ë¥¼ ì´ìš©í•´ ìœ„ë„, ê²½ë„ ì»¬ëŸ¼ ìƒì„± âœ¨
    # ì£¼ì†Œ ì§€ì˜¤ì½”ë”©ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìºì‹±ì„ í™œìš©í•˜ê³  ì§„í–‰ ìƒí™©ì„ í‘œì‹œ
    if 'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' in transport_df.columns:
        st.info("êµ¬ê¸‰ì°¨ ì´ì†¡ ë°ì´í„°ì˜ ì£¼ì†Œë¥¼ ìœ„ë„/ê²½ë„ë¡œ ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤. (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
        progress_bar = st.progress(0)
        
        # apply ëŒ€ì‹  ë°˜ë³µë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        latitudes = []
        longitudes = []
        total_addresses = len(transport_df)

        for i, address in enumerate(transport_df['ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ']):
            lat, lon = geocode_address(address)
            latitudes.append(lat)
            longitudes.append(lon)
            progress_bar.progress((i + 1) / total_addresses)
        
        transport_df['ì¶œë°œ_ìœ„ë„'] = latitudes
        transport_df['ì¶œë°œ_ê²½ë„'] = longitudes
        
        progress_bar.empty() # ì§„í–‰ë°” ì œê±°
        st.success("ì£¼ì†Œ ì§€ì˜¤ì½”ë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨í•œ (None ê°’) í–‰ ì œê±° ë˜ëŠ” ì²˜ë¦¬ (ì—¬ê¸°ì„œëŠ” ì œê±°)
        transport_df.dropna(subset=['ì¶œë°œ_ìœ„ë„', 'ì¶œë°œ_ê²½ë„'], inplace=True)
        st.info(f"ìœ íš¨í•œ ì¢Œí‘œê°€ ì—†ëŠ” {total_addresses - len(transport_df)}ê°œì˜ ì´ì†¡ ê¸°ë¡ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")


    transport_df.dropna(subset=['ì‹œë„ëª…'], inplace=True) # ì‹œë„ëª… ì—†ëŠ” í–‰ ì œê±°
    
    st.info("'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' ì»¬ëŸ¼ì„ ê¸°ë°˜ìœ¼ë¡œ 'ì‹œë„ëª…' ì»¬ëŸ¼ì„ ìƒì„±í•˜ê³  ë³´ì •í–ˆìŠµë‹ˆë‹¤.")
elif not transport_df.empty:
    st.warning("'transport_df'ì— 'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. 'ì‹œë„ëª…' ìƒì„±ì„ ê±´ë„ˆí‚µë‹ˆë‹¤.")
# --- âœ¨ ì „ì²˜ë¦¬ ë âœ¨ ---

time_df = load_time_data(time_json_path)
month_df = load_month_data(month_json_path)

place_for_osmnx = "Yongin-si, Gyeonggi-do, South Korea" # ì´ ë³€ìˆ˜ì™€ ì¼ì¹˜ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.
road_graph = load_road_network_from_osmnx(place_for_osmnx) 


# -------------------------------
# ì‚¬ì´ë“œë°” ì‚¬ìš©ì ìƒí˜¸ì‘ìš©
# -------------------------------
st.sidebar.title("ì‚¬ìš©ì ì„¤ì •")
if not time_df.empty and not month_df.empty:
    all_regions = set(time_df['ì‹œë„']) | set(month_df['ì‹œë„'])
    if not transport_df.empty and 'ì‹œë„ëª…' in transport_df.columns:
        all_regions |= set(transport_df['ì‹œë„ëª…'].unique()) 
    
    if all_regions:
        region = st.sidebar.selectbox("ì§€ì—­ ì„ íƒ", sorted(list(all_regions)))
    else:
        st.sidebar.warning("ë°ì´í„°ì— ê³µí†µ ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        region = None
else:
    st.sidebar.warning("ì‹œê°„ëŒ€ë³„ ë˜ëŠ” ì›”ë³„ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    region = None


# -------------------------------
# 1ï¸âƒ£ ì‘ê¸‰í™˜ì ì´ì†¡ í˜„í™©
# -------------------------------
st.subheader("1ï¸âƒ£ ì‘ê¸‰í™˜ì ì´ì†¡ í˜„í™© ë¶„ì„")
if not transport_df.empty:
    st.dataframe(transport_df.head())
    if st.checkbox("ğŸ“Œ ì´ì†¡ ë°ì´í„° ìš”ì•½ í†µê³„ ë³´ê¸°"):
        st.write(transport_df.describe(include='all'))
    
    if 'ì‹œë„ëª…' in transport_df.columns and transport_df['ì‹œë„ëª…'].notna().any(): 
        fig1, ax1 = plt.subplots(figsize=(10, 5))
        if region and region in transport_df['ì‹œë„ëª…'].unique():
            transport_df[transport_df['ì‹œë„ëª…'] == region].groupby('ì‹œë„ëª…').size().plot(kind='barh', ax=ax1, color='skyblue') 
            ax1.set_title(f"{region} ì‹œë„ë³„ ì´ì†¡ ê±´ìˆ˜")
        else:
            transport_df.groupby('ì‹œë„ëª…').size().sort_values(ascending=False).plot(kind='barh', ax=ax1, color='skyblue') 
            ax1.set_title("ì‹œë„ë³„ ì´ì†¡ ê±´ìˆ˜")
        
        ax1.set_xlabel("ê±´ìˆ˜")
        ax1.set_ylabel("ì‹œë„")
        plt.tight_layout() 
        st.pyplot(fig1)
    else:
        st.warning("ì´ì†¡ ë°ì´í„°ì— 'ì‹œë„ëª…' ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ìœ íš¨í•œ ì‹œë„ëª… ê°’ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.warning("ì´ì†¡ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œì™€ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# -------------------------------
# 2ï¸âƒ£ ì‹œê°„ëŒ€ë³„ ë¶„ì„
# -------------------------------
st.subheader("2ï¸âƒ£ ì‹œê°„ëŒ€ë³„ ì‘ê¸‰ì‹¤ ì´ìš© í˜„í™© (2023)")
if not time_df.empty and region:
    time_row = time_df[time_df['ì‹œë„'] == region]
    if not time_row.empty:
        time_row_data = time_row.iloc[0, 1:]
        fig2, ax2 = plt.subplots()
        time_row_data.plot(kind='bar', color='deepskyblue', ax=ax2)
        ax2.set_ylabel("ì´ìš© ê±´ìˆ˜")
        ax2.set_xlabel("ì‹œê°„ëŒ€")
        ax2.set_title(f"{region} ì‹œê°„ëŒ€ë³„ ì‘ê¸‰ì‹¤ ì´ìš©")
        st.pyplot(fig2)
    else:
        st.warning(f"'{region}' ì§€ì—­ì— ëŒ€í•œ ì‹œê°„ëŒ€ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.warning("ì‹œê°„ëŒ€ë³„ ë°ì´í„° ë¡œë“œì— ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§€ì—­ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# -------------------------------
# 3ï¸âƒ£ ì›”ë³„ ë¶„ì„
# -------------------------------
st.subheader("3ï¸âƒ£ ì›”ë³„ ì‘ê¸‰ì‹¤ ì´ìš© í˜„í™© (2023)")
if not month_df.empty and region:
    month_row = month_df[month_df['ì‹œë„'] == region]
    if not month_row.empty:
        month_row_data = month_row.iloc[0, 1:]
        fig3, ax3 = plt.subplots()
        month_row_data.plot(kind='line', marker='o', color='seagreen', ax=ax3)
        ax3.set_ylabel("ì´ìš© ê±´ìˆ˜")
        ax3.set_xlabel("ì›”")
        ax3.set_title(f"{region} ì›”ë³„ ì‘ê¸‰ì‹¤ ì´ìš©")
        st.pyplot(fig3)
    else:
        st.warning(f"'{region}' ì§€ì—­ì— ëŒ€í•œ ì›”ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.warning("ì›”ë³„ ë°ì´í„° ë¡œë“œì— ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§€ì—­ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# -------------------------------
# 4ï¸âƒ£ ë„ë¡œë§ ê·¸ë˜í”„ ì •ë³´
# -------------------------------
st.subheader("ğŸ›£ï¸ ë„ë¡œë§ ê·¸ë˜í”„ ì •ë³´")
if road_graph:
    st.write(f"**ë¡œë“œëœ ë„ë¡œë§ ê·¸ë˜í”„ (`{place_for_osmnx}`):**") 
    st.write(f"  - ë…¸ë“œ ìˆ˜: {road_graph.number_of_nodes()}ê°œ")
    st.write(f"  - ê°„ì„  ìˆ˜: {road_graph.number_of_edges()}ê°œ")
    
    st.write("ê°„ë‹¨í•œ ë„ë¡œë§ ì§€ë„ ì‹œê°í™” (ë…¸ë“œì™€ ê°„ì„ ):")
    fig, ax = ox.plot_graph(road_graph, show=False, bgcolor='white', node_color='red', node_size=5, edge_color='gray', edge_linewidth=0.5)
    st.pyplot(fig) 
    st.caption("ì°¸ê³ : ì „ì²´ ë„ë¡œë§ì€ ë³µì¡í•˜ì—¬ ë¡œë”©ì´ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

else:
    st.warning("ë„ë¡œë§ ê·¸ë˜í”„ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì§€ì •ëœ ì§€ì—­ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")


# -------------------------------
# 5ï¸âƒ£ ìš°ì„ ìˆœìœ„ í ì‹œë®¬ë ˆì´ì…˜
# -------------------------------
st.subheader("5ï¸âƒ£ ì‘ê¸‰ ëŒ€ê¸° ì‹œë®¬ë ˆì´ì…˜ (ìŠ¤íƒ/í ëª¨ë¸)")
mode = st.radio("ëŒ€ê¸° ë°©ì‹ ì„ íƒ", ['í (ì„ ì…ì„ ì¶œ)', 'ìŠ¤íƒ (í›„ì…ì„ ì¶œ)'])
patient_input = st.text_input("í™˜ì ì´ë¦„ (ì‰¼í‘œë¡œ êµ¬ë¶„)", "í™ê¸¸ë™,ê¹€ì˜í¬,ì´ì² ìˆ˜")
patients = [p.strip() for p in patient_input.split(',') if p.strip()]

if patients:
    st.write("**ì§„ë£Œ ìˆœì„œ:**")
    if mode == 'í (ì„ ì…ì„ ì¶œ)':
        queue = deque(patients)
        st.write(list(queue))
    else:
        st.write(list(reversed(patients)))

st.markdown("---")
st.caption("â“’ 2025 ìŠ¤ë§ˆíŠ¸ ì‘ê¸‰ì˜ë£Œ ë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸ - SDG 3.8 ë³´ê±´ì„œë¹„ìŠ¤ ì ‘ê·¼ì„± ê°œì„ ")
