import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
from collections import deque
import os
import chardet

# ê³µê°„ ë°ì´í„° ë° ê·¸ë˜í”„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ (geopandas ëŒ€ì‹  osmnx ì‚¬ìš©)
# import geopandas as gpd # geopandasëŠ” ë” ì´ìƒ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
import networkx as nx
# from shapely.geometry import Point, LineString # shapelyë„ osmnx ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
import osmnx as ox # âœ¨ osmnx ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ âœ¨

# Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic' # Windows ì‚¬ìš©ì
# plt.rcParams['font.family'] = 'AppleGothic' # macOS ì‚¬ìš©ì
plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€

st.set_page_config(page_title="ì‘ê¸‰ì˜ë£Œ ì´ì†¡ ë° ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸš‘ ì‘ê¸‰í™˜ì ì´ì†¡ ë° ì‘ê¸‰ì‹¤ ì´ìš© ë¶„ì„")

# -------------------------------
# íŒŒì¼ ê²½ë¡œ
# -------------------------------
transport_path = "data/ì •ë³´_01_í–‰ì •ì•ˆì „ë¶€_ì‘ê¸‰í™˜ìì´ì†¡ì—…(ê³µê³µë°ì´í„°í¬í„¸).csv"
time_json_path = "data/ì •ë³´_SOS_03.json"
month_json_path = "data/ì •ë³´_SOS_02.json"
# ğŸ›£ï¸ ë„ë¡œë§ SHP íŒŒì¼ ê²½ë¡œëŠ” ì´ì œ í•„ìš” ì—†ìŠµë‹ˆë‹¤. (osmnxê°€ ì§ì ‘ ë‹¤ìš´ë¡œë“œ)

# -------------------------------
# ë°ì´í„° ë¡œë”© í•¨ìˆ˜
# -------------------------------

# ... (load_transport_data í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€) ...
@st.cache_data
def load_transport_data(path):
    if not os.path.exists(path):
        st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()
    
    try:
        possible_encodings = ['cp949', 'euc-kr', 'utf-8', 'utf-8-sig'] 
        possible_seps = [',', ';', '\t', '|']

        df = None
        for enc in possible_encodings:
            for sep in possible_seps:
                try:
                    df = pd.read_csv(path, encoding=enc, sep=sep, on_bad_lines='skip', engine='python')
                    if not df.empty and len(df.columns) > 1:
                        st.info(f"'{path}' íŒŒì¼ì„ '{enc}' ì¸ì½”ë”©, êµ¬ë¶„ì '{sep}'ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                        return df
                    else:
                        continue 
                except (UnicodeDecodeError, pd.errors.ParserError) as e:
                    continue
                except Exception as e:
                    st.error(f"'{path}' íŒŒì¼ì„ ì—¬ëŠ” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (ì¸ì½”ë”©: {enc}, êµ¬ë¶„ì: {sep}): {e}")
                    continue
        
        st.error(f"'{path}' íŒŒì¼ì„ ì§€ì›ë˜ëŠ” ì–´ë–¤ ì¸ì½”ë”©/êµ¬ë¶„ìë¡œë„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()

    except Exception as e:
        st.error(f"'{path}' íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ìµœìƒìœ„ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# ... (load_time_data í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€) ...
@st.cache_data
def load_time_data(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            raw = json.load(f)
        records = raw[4:]
        time_cols = {
            'col5': '00-03ì‹œ', 'col6': '03-06ì‹œ', 'col7': '06-09ì‹œ', 'col8': '09-12ì‹œ',
            'col9': '12-15ì‹œ', 'col10': '15-18ì‹œ', 'col11': '18-21ì‹œ', 'col12': '21-24ì‹œ'
        }
        rows = []
        for row in records:
            region = row.get('col3')
            if region == "ì „ì²´" or not region:
                continue
            values = [int(row.get(c, "0").replace(",", "")) for c in time_cols.keys()]
            rows.append([region] + values)
        df = pd.DataFrame(rows, columns=['ì‹œë„'] + list(time_cols.values()))
        st.info(f"'{path}' JSON íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return df
    except FileNotFoundError:
        st.error(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()
    except json.JSONDecodeError as e:
        st.error(f"'{path}' JSON íŒŒì¼ ë””ì½”ë”© ì˜¤ë¥˜: {e}. íŒŒì¼ ë‚´ìš©ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"'{path}' JSON íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# ... (load_month_data í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€) ...
@st.cache_data
def load_month_data(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            raw = json.load(f)
        records = raw[4:]
        month_cols = {
            'col7': '1ì›”', 'col8': '2ì›”', 'col9': '3ì›”', 'col10': '4ì›”',
            'col11': '5ì›”', 'col12': '6ì›”', 'col13': '7ì›”', 'col14': '8ì›”',
            'col15': '9ì›”', 'col16': '10ì›”', 'col17': '11ì›”', 'col18': '12ì›”'
        }
        rows = []
        for row in records:
            region = row.get('col3')
            if region == "ì „ì²´" or not region:
                continue
            values = [int(row.get(c, "0").replace(",", "")) for c in month_cols.keys()]
            rows.append([region] + values)
        df = pd.DataFrame(rows, columns=['ì‹œë„'] + list(month_cols.values()))
        st.info(f"'{path}' JSON íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return df
    except FileNotFoundError:
        st.error(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()
    except json.JSONDecodeError as e:
        st.error(f"'{path}' JSON íŒŒì¼ ë””ì½”ë”© ì˜¤ë¥˜: {e}. íŒŒì¼ ë‚´ìš©ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"'{path}' JSON íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# ğŸ›£ï¸ osmnxë¥¼ ì‚¬ìš©í•˜ì—¬ ë„ë¡œë§ ê·¸ë˜í”„ë¥¼ ë¡œë“œí•˜ê³  networkx ê·¸ë˜í”„ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
@st.cache_data
def load_road_network_from_osmnx(place_name):
    try:
        # osmnxë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì§€ì—­ì˜ ë„ë¡œë§ ê·¸ë˜í”„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        # network_type='drive'ëŠ” ì°¨ëŸ‰ì´ í†µí–‰ ê°€ëŠ¥í•œ ë„ë¡œë§Œ ê°€ì ¸ì˜¤ë„ë¡ í•©ë‹ˆë‹¤.
        # simplify=TrueëŠ” ë³µì¡í•œ ì§€ì˜¤ë©”íŠ¸ë¦¬ë¥¼ ë‹¨ìˆœí™”í•˜ì—¬ ê·¸ë˜í”„ í¬ê¸°ë¥¼ ì¤„ì…ë‹ˆë‹¤.
        # retain_all=TrueëŠ” ê·¸ë˜í”„ì˜ ëª¨ë“  ì—°ê²° ìš”ì†Œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤. (í° ê·¸ë˜í”„ì˜ ê²½ìš° False ê³ ë ¤)
        # custom_settingsëŠ” í•„ìš”ì— ë”°ë¼ ì¶”ê°€ì ì¸ Overpass API ì„¤ì • ê°€ëŠ¥
        st.info(f"'{place_name}' ì§€ì—­ì˜ ë„ë¡œë§ ë°ì´í„°ë¥¼ OpenStreetMapì—ì„œ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        
        G = ox.graph_from_place(place_name, network_type='drive', simplify=True, retain_all=True)
        
        # ê·¸ë˜í”„ì˜ ì¢Œí‘œê³„ê°€ ìœ„ë„/ê²½ë„(EPSG:4326)ì¸ì§€ í™•ì¸ (osmnxëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì´ í˜•ì‹ì„ ë”°ë¦„)
        # ox.add_edge_speeds(G) # í•„ìš”ì‹œ ë„ë¡œë³„ ê¸°ë³¸ ì†ë„ ì¶”ê°€
        # ox.add_edge_travel_times(G) # í•„ìš”ì‹œ ê° ê°„ì„ ì˜ í†µí–‰ ì‹œê°„ ê³„ì‚° (ì†ë„ ê¸°ë°˜)
        
        st.success(f"'{place_name}' ë„ë¡œë§ì„ NetworkX ê·¸ë˜í”„ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤. ë…¸ë“œ ìˆ˜: {G.number_of_nodes()}, ê°„ì„  ìˆ˜: {G.number_of_edges()}")
        return G

    except Exception as e:
        st.error(f"'{place_name}' ë„ë¡œë§ ë°ì´í„°ë¥¼ OpenStreetMapì—ì„œ ê°€ì ¸ì˜¤ê³  ê·¸ë˜í”„ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.warning("ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜, ì§€ì—­ ì´ë¦„ì´ ì •í™•í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”. ë„ˆë¬´ í° ì§€ì—­ì„ ì§€ì •í•˜ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ë‚˜ íƒ€ì„ì•„ì›ƒì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return None

# -------------------------------
# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# -------------------------------
transport_df = load_transport_data(transport_path)

# --- âœ¨ transport_df ì „ì²˜ë¦¬: 'ì‹œë„ëª…' ì»¬ëŸ¼ ìƒì„± ë° ë³´ì • âœ¨ ---
if not transport_df.empty and 'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' in transport_df.columns:
    def extract_sido(address):
        if pd.isna(address):
            return None
        
        addr_str = str(address).strip() 
        if not addr_str: 
            return None

        parts = addr_str.split(' ')
        if not parts: 
            return None

        first_part = parts[0]

        if 'ì„¸ì¢…' in first_part:
            return 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ'
        
        korean_sido_list = ["ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°ê´‘ì—­ì‹œ", "ëŒ€êµ¬ê´‘ì—­ì‹œ", "ì¸ì²œê´‘ì—­ì‹œ", "ê´‘ì£¼ê´‘ì—­ì‹œ",
                                 "ëŒ€ì „ê´‘ì—­ì‹œ", "ìš¸ì‚°ê´‘ì—­ì‹œ", "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", "ê²½ê¸°ë„", "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
                                 "ì¶©ì²­ë¶ë„", "ì¶©ì²­ë‚¨ë„", "ì „ë¼ë¶ë„", "ì „ë¼ë‚¨ë„", "ê²½ìƒë¶ë„", "ê²½ìƒë‚¨ë„",
                                 "ì œì£¼íŠ¹ë³„ìì¹˜ë„"]
            
        for sido in korean_sido_list:
            if first_part in sido: 
                return sido 
        
        for part in parts:
            if isinstance(part, str) and ('íŠ¹ë³„ì‹œ' in part or 'ê´‘ì—­ì‹œ' in part or 'ìì¹˜ì‹œ' in part or 'ìì¹˜ë„' in part):
                if 'ê°•ì›' in part or 'ì „ë¼' in part or 'ì¶©ì²­' in part or 'ê²½ìƒ' in part or 'ê²½ê¸°' in part or 'ì œì£¼' in part:
                    if len(parts) > 1:
                        return f"{parts[0]}{part}"
                    else:
                        return part
                return part

        return None 


    transport_df['ì‹œë„ëª…'] = transport_df['ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ'].apply(extract_sido)

    transport_df.dropna(subset=['ì‹œë„ëª…'], inplace=True)
    
    st.info("'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' ì»¬ëŸ¼ì„ ê¸°ë°˜ìœ¼ë¡œ 'ì‹œë„ëª…' ì»¬ëŸ¼ì„ ìƒì„±í•˜ê³  ë³´ì •í–ˆìŠµë‹ˆë‹¤.")
elif not transport_df.empty:
    st.warning("'transport_df'ì— 'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. 'ì‹œë„ëª…' ìƒì„±ì„ ê±´ë„ˆí‚µë‹ˆë‹¤.")
# --- âœ¨ ì „ì²˜ë¦¬ ë âœ¨ ---

time_df = load_time_data(time_json_path)
month_df = load_month_data(month_json_path)

# ğŸ›£ï¸ ë„ë¡œë§ ê·¸ë˜í”„ ë¡œë“œ (osmnx í•¨ìˆ˜ë¡œ ë³€ê²½)
# 'Yongin-si, Gyeonggi-do, South Korea' ë˜ëŠ” 'ì„œìš¸íŠ¹ë³„ì‹œ' ë“±ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
road_graph = load_road_network_from_osmnx("Yongin-si, Gyeonggi-do, South Korea") 


# -------------------------------
# ì‚¬ì´ë“œë°” ì‚¬ìš©ì ìƒí˜¸ì‘ìš©
# -------------------------------
st.sidebar.title("ì‚¬ìš©ì ì„¤ì •")
if not time_df.empty and not month_df.empty:
    # transport_dfì˜ ì‹œë„ëª…ë„ ì¶”ê°€í•˜ì—¬ ê³µí†µ ì§€ì—­ ì„ íƒì— í™œìš©
    all_regions = set(time_df['ì‹œë„']) | set(month_df['ì‹œë„'])
    if not transport_df.empty and 'ì‹œë„ëª…' in transport_df.columns:
        all_regions |= set(transport_df['ì‹œë„ëª…'].unique()) # transport_dfì˜ ì‹œë„ëª…ë„ ì¶”ê°€
    
    if all_regions:
        region = st.sidebar.selectbox("ì§€ì—­ ì„ íƒ", sorted(list(all_regions)))
    else:
        st.sidebar.warning("ë°ì´í„°ì— ê³µí†µ ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        region = None
else:
    st.sidebar.warning("ì‹œê°„ëŒ€ë³„ ë˜ëŠ” ì›”ë³„ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    region = None


# -------------------------------
# 1ï¸âƒ£ ì‘ê¸‰í™˜ì ì´ì†¡ í˜„í™©
# -------------------------------
st.subheader("1ï¸âƒ£ ì‘ê¸‰í™˜ì ì´ì†¡ í˜„í™© ë¶„ì„")
if not transport_df.empty:
    st.dataframe(transport_df.head())
    if st.checkbox("ğŸ“Œ ì´ì†¡ ë°ì´í„° ìš”ì•½ í†µê³„ ë³´ê¸°"):
        st.write(transport_df.describe(include='all'))
    
    if 'ì‹œë„ëª…' in transport_df.columns and transport_df['ì‹œë„ëª…'].notna().any(): 
        fig1, ax1 = plt.subplots(figsize=(10, 5))
        # íŠ¹ì • ì§€ì—­ì´ ì„ íƒë˜ì—ˆì„ ê²½ìš° í•´ë‹¹ ì§€ì—­ë§Œ í•„í„°ë§í•˜ì—¬ ì´ì†¡ ê±´ìˆ˜ ì‹œê°í™”
        if region and region in transport_df['ì‹œë„ëª…'].unique():
            transport_df[transport_df['ì‹œë„ëª…'] == region].groupby('ì‹œë„ëª…').size().plot(kind='barh', ax=ax1, color='skyblue') 
            ax1.set_title(f"{region} ì‹œë„ë³„ ì´ì†¡ ê±´ìˆ˜") # ì œëª© ë³€ê²½
        else:
            transport_df.groupby('ì‹œë„ëª…').size().sort_values(ascending=False).plot(kind='barh', ax=ax1, color='skyblue') 
            ax1.set_title("ì‹œë„ë³„ ì´ì†¡ ê±´ìˆ˜")
        
        ax1.set_xlabel("ê±´ìˆ˜")
        ax1.set_ylabel("ì‹œë„")
        plt.tight_layout() 
        st.pyplot(fig1)
    else:
        st.warning("ì´ì†¡ ë°ì´í„°ì— 'ì‹œë„ëª…' ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ìœ íš¨í•œ ì‹œë„ëª… ê°’ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.warning("ì´ì†¡ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œì™€ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# -------------------------------
# 2ï¸âƒ£ ì‹œê°„ëŒ€ë³„ ë¶„ì„
# -------------------------------
st.subheader("2ï¸âƒ£ ì‹œê°„ëŒ€ë³„ ì‘ê¸‰ì‹¤ ì´ìš© í˜„í™© (2023)")
if not time_df.empty and region:
    # ì„ íƒëœ ì§€ì—­ì— ëŒ€í•œ ì‹œê°„ëŒ€ë³„ ë°ì´í„°ë¥¼ ì°¾ìŒ
    time_row = time_df[time_df['ì‹œë„'] == region]
    if not time_row.empty:
        time_row_data = time_row.iloc[0, 1:]
        fig2, ax2 = plt.subplots()
        time_row_data.plot(kind='bar', color='deepskyblue', ax=ax2)
        ax2.set_ylabel("ì´ìš© ê±´ìˆ˜")
        ax2.set_xlabel("ì‹œê°„ëŒ€")
        ax2.set_title(f"{region} ì‹œê°„ëŒ€ë³„ ì‘ê¸‰ì‹¤ ì´ìš©")
        st.pyplot(fig2)
    else:
        st.warning(f"'{region}' ì§€ì—­ì— ëŒ€í•œ ì‹œê°„ëŒ€ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.warning("ì‹œê°„ëŒ€ë³„ ë°ì´í„° ë¡œë“œì— ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§€ì—­ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# -------------------------------
# 3ï¸âƒ£ ì›”ë³„ ë¶„ì„
# -------------------------------
st.subheader("3ï¸âƒ£ ì›”ë³„ ì‘ê¸‰ì‹¤ ì´ìš© í˜„í™© (2023)")
if not month_df.empty and region:
    # ì„ íƒëœ ì§€ì—­ì— ëŒ€í•œ ì›”ë³„ ë°ì´í„°ë¥¼ ì°¾ìŒ
    month_row = month_df[month_df['ì‹œë„'] == region]
    if not month_row.empty:
        month_row_data = month_row.iloc[0, 1:]
        fig3, ax3 = plt.subplots()
        month_row_data.plot(kind='line', marker='o', color='seagreen', ax=ax3)
        ax3.set_ylabel("ì´ìš© ê±´ìˆ˜")
        ax3.set_xlabel("ì›”")
        ax3.set_title(f"{region} ì›”ë³„ ì‘ê¸‰ì‹¤ ì´ìš©")
        st.pyplot(fig3)
    else:
        st.warning(f"'{region}' ì§€ì—­ì— ëŒ€í•œ ì›”ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.warning("ì›”ë³„ ë°ì´í„° ë¡œë“œì— ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§€ì—­ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# -------------------------------
# 4ï¸âƒ£ ë„ë¡œë§ ê·¸ë˜í”„ ì •ë³´ (osmnxë¡œ ë³€ê²½)
# -------------------------------
st.subheader("ğŸ›£ï¸ ë„ë¡œë§ ê·¸ë˜í”„ ì •ë³´")
if road_graph:
    st.write(f"**ë¡œë“œëœ ë„ë¡œë§ ê·¸ë˜í”„ (`{road_graph.graph['place']}`):**")
    st.write(f"  - ë…¸ë“œ ìˆ˜: {road_graph.number_of_nodes()}ê°œ")
    st.write(f"  - ê°„ì„  ìˆ˜: {road_graph.number_of_edges()}ê°œ")
    
    # ë§µ ìœ„ì— ê·¸ë˜í”„ ì‹œê°í™” (ê°„ë‹¨í•œ ì˜ˆì‹œ)
    st.write("ê°„ë‹¨í•œ ë„ë¡œë§ ì§€ë„ ì‹œê°í™” (ë…¸ë“œì™€ ê°„ì„ ):")
    fig, ax = ox.plot_graph(road_graph, show=False, close=False, bgcolor='white', node_color='red', node_size=5, edge_color='gray', edge_linewidth=0.5)
    st.pyplot(fig) # Streamlitì— Matplotlib ê·¸ë¦¼ í‘œì‹œ
    st.caption("ì°¸ê³ : ì „ì²´ ë„ë¡œë§ì€ ë³µì¡í•˜ì—¬ ë¡œë”©ì´ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

else:
    st.warning("ë„ë¡œë§ ê·¸ë˜í”„ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì§€ì •ëœ ì§€ì—­ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")


# -------------------------------
# 5ï¸âƒ£ ìš°ì„ ìˆœìœ„ í ì‹œë®¬ë ˆì´ì…˜
# -------------------------------
st.subheader("5ï¸âƒ£ ì‘ê¸‰ ëŒ€ê¸° ì‹œë®¬ë ˆì´ì…˜ (ìŠ¤íƒ/í ëª¨ë¸)")
mode = st.radio("ëŒ€ê¸° ë°©ì‹ ì„ íƒ", ['í (ì„ ì…ì„ ì¶œ)', 'ìŠ¤íƒ (í›„ì…ì„ ì¶œ)'])
patient_input = st.text_input("í™˜ì ì´ë¦„ (ì‰¼í‘œë¡œ êµ¬ë¶„)", "í™ê¸¸ë™,ê¹€ì˜í¬,ì´ì² ìˆ˜")
patients = [p.strip() for p in patient_input.split(',') if p.strip()]

if patients:
    st.write("**ì§„ë£Œ ìˆœì„œ:**")
    if mode == 'í (ì„ ì…ì„ ì¶œ)':
        queue = deque(patients)
        st.write(list(queue))
    else:
        st.write(list(reversed(patients)))

st.markdown("---")
st.caption("â“’ 2025 ìŠ¤ë§ˆíŠ¸ ì‘ê¸‰ì˜ë£Œ ë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸ - SDG 3.8 ë³´ê±´ì„œë¹„ìŠ¤ ì ‘ê·¼ì„± ê°œì„ ")
