import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
from collections import deque
import os
import chardet

# Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
# Streamlit Cloud í™˜ê²½ì—ì„œëŠ” í°íŠ¸ ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ì˜ˆë¥¼ ë“¤ì–´, .streamlit/config.toml íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì¶”ê°€ (Streamlit Cloudì—ì„œ)
# [theme]
# fontFamily = "Malgun Gothic"
# (ë¡œì»¬ í™˜ê²½ì˜ ê²½ìš°)
plt.rcParams['font.family'] = 'Malgun Gothic' # Windows ì‚¬ìš©ì
# plt.rcParams['font.family'] = 'AppleGothic' # macOS ì‚¬ìš©ì
plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€

st.set_page_config(page_title="ì‘ê¸‰ì˜ë£Œ ì´ì†¡ ë° ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸš‘ ì‘ê¸‰í™˜ì ì´ì†¡ ë° ì‘ê¸‰ì‹¤ ì´ìš© ë¶„ì„")

# -------------------------------
# íŒŒì¼ ê²½ë¡œ
# -------------------------------
transport_path = "data/ì •ë³´_01_í–‰ì •ì•ˆì „ë¶€_ì‘ê¸‰í™˜ìì´ì†¡ì—…(ê³µê³µë°ì´í„°í¬í„¸).csv"
time_json_path = "data/ì •ë³´_SOS_03.json"
month_json_path = "data/ì •ë³´_SOS_02.json"

# -------------------------------
# ë°ì´í„° ë¡œë”© í•¨ìˆ˜
# -------------------------------

# CSV íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
@st.cache_data
def load_transport_data(path):
    if not os.path.exists(path):
        st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()
    
    try:
        # Notepad++ì—ì„œ EUC-KRë¡œ í™•ì¸ë˜ì—ˆìœ¼ë‚˜, 'euc-kr' decode ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìœ¼ë¯€ë¡œ
        # 'cp949'ë¥¼ ê°€ì¥ ë¨¼ì € ì‹œë„í•˜ê³  ê·¸ ë‹¤ìŒ 'euc-kr'ì„ ì‹œë„í•©ë‹ˆë‹¤.
        # 'cp949'ëŠ” 'euc-kr'ì˜ í™•ì¥íŒìœ¼ë¡œ ë” ë§ì€ ë¬¸ìë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
        # ì´í›„ utf-8 ë° utf-8-sigë„ ì‹œë„í•©ë‹ˆë‹¤.
        possible_encodings = ['cp949', 'euc-kr', 'utf-8', 'utf-8-sig'] 
        possible_seps = [',', ';', '\t', '|']

        df = None
        for enc in possible_encodings:
            for sep in possible_seps:
                try:
                    df = pd.read_csv(path, encoding=enc, sep=sep, on_bad_lines='skip', engine='python')
                    
                    if not df.empty and len(df.columns) > 1:
                        st.info(f"'{path}' íŒŒì¼ì„ '{enc}' ì¸ì½”ë”©, êµ¬ë¶„ì '{sep}'ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                        return df
                    else:
                        continue # ë¹ˆ DataFrameì´ê±°ë‚˜ ì»¬ëŸ¼ì´ í•˜ë‚˜ë©´ ì˜ëª» ë¡œë“œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                except (UnicodeDecodeError, pd.errors.ParserError) as e:
                    # ì¸ì½”ë”© ì˜¤ë¥˜ ë˜ëŠ” íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¤ìŒ ì¡°í•© ì‹œë„
                    # st.warning(f"'{path}' ë¡œë“œ ì‹¤íŒ¨ (ì¸ì½”ë”©: {enc}, êµ¬ë¶„ì: {sep}): {e}") # ë””ë²„ê¹…ìš©
                    continue
                except Exception as e:
                    # ì˜ˆìƒì¹˜ ëª»í•œ ë‹¤ë¥¸ ì˜¤ë¥˜ ë°œìƒ ì‹œ
                    st.error(f"'{path}' íŒŒì¼ì„ ì—¬ëŠ” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (ì¸ì½”ë”©: {enc}, êµ¬ë¶„ì: {sep}): {e}")
                    continue
        
        st.error(f"'{path}' íŒŒì¼ì„ ì§€ì›ë˜ëŠ” ì–´ë–¤ ì¸ì½”ë”©/êµ¬ë¶„ìë¡œë„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()

    except Exception as e:
        st.error(f"'{path}' íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ìµœìƒìœ„ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()


@st.cache_data
def load_time_data(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            raw = json.load(f)
        records = raw[4:]
        time_cols = {
            'col5': '00-03ì‹œ', 'col6': '03-06ì‹œ', 'col7': '06-09ì‹œ', 'col8': '09-12ì‹œ',
            'col9': '12-15ì‹œ', 'col10': '15-18ì‹œ', 'col11': '18-21ì‹œ', 'col12': '21-24ì‹œ'
        }
        rows = []
        for row in records:
            region = row.get('col3')
            if region == "ì „ì²´" or not region:
                continue
            values = [int(row.get(c, "0").replace(",", "")) for c in time_cols.keys()]
            rows.append([region] + values)
        df = pd.DataFrame(rows, columns=['ì‹œë„'] + list(time_cols.values()))
        st.info(f"'{path}' JSON íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return df
    except FileNotFoundError:
        st.error(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()
    except json.JSONDecodeError as e:
        st.error(f"'{path}' JSON íŒŒì¼ ë””ì½”ë”© ì˜¤ë¥˜: {e}. íŒŒì¼ ë‚´ìš©ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"'{path}' JSON íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

@st.cache_data
def load_month_data(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            raw = json.load(f)
        records = raw[4:]
        month_cols = {
            'col7': '1ì›”', 'col8': '2ì›”', 'col9': '3ì›”', 'col10': '4ì›”',
            'col11': '5ì›”', 'col12': '6ì›”', 'col13': '7ì›”', 'col14': '8ì›”',
            'col15': '9ì›”', 'col16': '10ì›”', 'col17': '11ì›”', 'col18': '12ì›”'
        }
        rows = []
        for row in records:
            region = row.get('col3')
            if region == "ì „ì²´" or not region:
                continue
            values = [int(row.get(c, "0").replace(",", "")) for c in month_cols.keys()]
            rows.append([region] + values)
        df = pd.DataFrame(rows, columns=['ì‹œë„'] + list(month_cols.values()))
        st.info(f"'{path}' JSON íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return df
    except FileNotFoundError:
        st.error(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return pd.DataFrame()
    except json.JSONDecodeError as e:
        st.error(f"'{path}' JSON íŒŒì¼ ë””ì½”ë”© ì˜¤ë¥˜: {e}. íŒŒì¼ ë‚´ìš©ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"'{path}' JSON íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# -------------------------------
# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
transport_df = load_transport_data(transport_path)

# --- âœ¨ transport_df ì „ì²˜ë¦¬: 'ì‹œë„ëª…' ì»¬ëŸ¼ ìƒì„± ë° ë³´ì • âœ¨ ---
if not transport_df.empty and 'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' in transport_df.columns:
    def extract_sido(address):
        if pd.isna(address):
            return None
        
        addr_str = str(address).strip() # ì•ë’¤ ê³µë°± ì œê±°
        if not addr_str: # ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš°
            return None

        parts = addr_str.split(' ')
        if not parts: # ê³µë°±ìœ¼ë¡œ ë‚˜ëˆ´ì„ ë•Œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            return None

        first_part = parts[0]

        # ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œì™€ ê°™ì´ ë‹¨ì¼ ë‹¨ì–´ì´ì§€ë§Œ ê¸´ ê²½ìš°ë¥¼ ë¨¼ì € ì²˜ë¦¬
        if 'ì„¸ì¢…' in first_part:
            return 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ'
        
        # ì¼ë°˜ì ì¸ ì‹œ/ë„ëª… íŒ¨í„´ (2~4ê¸€ì)
        if len(first_part) <= 4:
            # "ì„œìš¸", "ê²½ê¸°", "ì¸ì²œ" ë“±
            # ì—¬ê¸°ì— ì‹œë„ ëª©ë¡ì„ ëª…ì‹œì ìœ¼ë¡œ ë„£ì–´ ë” ì •í™•í•˜ê²Œ í•„í„°ë§í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
            korean_sido_list = ["ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°ê´‘ì—­ì‹œ", "ëŒ€êµ¬ê´‘ì—­ì‹œ", "ì¸ì²œê´‘ì—­ì‹œ", "ê´‘ì£¼ê´‘ì—­ì‹œ",
                                 "ëŒ€ì „ê´‘ì—­ì‹œ", "ìš¸ì‚°ê´‘ì—­ì‹œ", "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", "ê²½ê¸°ë„", "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
                                 "ì¶©ì²­ë¶ë„", "ì¶©ì²­ë‚¨ë„", "ì „ë¼ë¶ë„", "ì „ë¼ë‚¨ë„", "ê²½ìƒë¶ë„", "ê²½ìƒë‚¨ë„",
                                 "ì œì£¼íŠ¹ë³„ìì¹˜ë„"]
            
            # ì£¼ì†Œì˜ ì²« ë¶€ë¶„ì´ ì‹¤ì œ ì‹œë„ëª… ëª©ë¡ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
            for sido in korean_sido_list:
                if first_part in sido: # ì˜ˆ: 'ì„œìš¸' in 'ì„œìš¸íŠ¹ë³„ì‹œ'
                    return sido # ì •í™•í•œ ì‹œë„ëª…ì„ ë°˜í™˜

        # íŠ¹ë³„ì‹œ, ê´‘ì—­ì‹œ, ìì¹˜ì‹œ/ë„ í¬í•¨í•˜ëŠ” ê²½ìš° ì²˜ë¦¬
        # 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„' ë“±
        for part in parts:
            if 'íŠ¹ë³„ì‹œ' in part or 'ê´‘ì—­ì‹œ' in part or 'ìì¹˜ì‹œ' in part or 'ìì¹˜ë„' in part:
                # 'ê°•ì›íŠ¹ë³„ìì¹˜ë„'ì²˜ëŸ¼ ë‘ ë‹¨ì–´ì¼ ê²½ìš°ë¥¼ ìœ„í•´ ì¡°ì •
                if 'ê°•ì›' in part or 'ì „ë¼' in part or 'ì¶©ì²­' in part or 'ê²½ìƒ' in part or 'ê²½ê¸°' in part:
                    return f"{parts[0]}{part}" # 'ê°•ì›' + 'íŠ¹ë³„ìì¹˜ë„'
                return part # 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ' ë“±

        return None # ì–´ë–¤ ì¡°ê±´ì—ë„ í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜


    transport_df['ì‹œë„ëª…'] = transport_df['ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ'].apply(extract_sido)

    # ì‹œë„ëª… ì»¬ëŸ¼ì— ìœ íš¨í•˜ì§€ ì•Šì€ (None) ê°’ì´ ë‚¨ì•„ìˆì„ ê²½ìš° ì œê±°
    # í˜¹ì€ 'ê¸°íƒ€' ë“±ìœ¼ë¡œ ì±„ìš¸ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤: transport_df['ì‹œë„ëª…'].fillna('ê¸°íƒ€', inplace=True)
    transport_df.dropna(subset=['ì‹œë„ëª…'], inplace=True)
    
    st.info("'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' ì»¬ëŸ¼ì„ ê¸°ë°˜ìœ¼ë¡œ 'ì‹œë„ëª…' ì»¬ëŸ¼ì„ ìƒì„±í•˜ê³  ë³´ì •í–ˆìŠµë‹ˆë‹¤.")
elif not transport_df.empty: # ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°
    st.warning("'transport_df'ì— 'ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. 'ì‹œë„ëª…' ìƒì„±ì„ ê±´ë„ˆí‚µë‹ˆë‹¤.")
# --- âœ¨ ì „ì²˜ë¦¬ ë âœ¨ ---
time_df = load_time_data(time_json_path)
month_df = load_month_data(month_json_path)


# -------------------------------
# ì‚¬ì´ë“œë°” ì‚¬ìš©ì ìƒí˜¸ì‘ìš©
# -------------------------------
st.sidebar.title("ì‚¬ìš©ì ì„¤ì •")
if not time_df.empty and not month_df.empty:
    common_regions = list(set(time_df['ì‹œë„']) & set(month_df['ì‹œë„']))
    if common_regions:
        region = st.sidebar.selectbox("ì§€ì—­ ì„ íƒ", sorted(common_regions))
    else:
        st.sidebar.warning("ì‹œê°„ëŒ€ë³„ ë° ì›”ë³„ ë°ì´í„°ì— ê³µí†µ ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        region = None
else:
    st.sidebar.warning("ì‹œê°„ëŒ€ë³„ ë˜ëŠ” ì›”ë³„ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    region = None


# -------------------------------
# 1ï¸âƒ£ ì‘ê¸‰í™˜ì ì´ì†¡ í˜„í™©
# -------------------------------
st.subheader("1ï¸âƒ£ ì‘ê¸‰í™˜ì ì´ì†¡ í˜„í™© ë¶„ì„")
if not transport_df.empty:
    st.dataframe(transport_df.head())
    if st.checkbox("ğŸ“Œ ì´ì†¡ ë°ì´í„° ìš”ì•½ í†µê³„ ë³´ê¸°"):
        st.write(transport_df.describe(include='all'))
    
    # 'ì‹œë„ëª…' ì»¬ëŸ¼ì´ ì´ì œ ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ, ì´ ì¡°ê±´ë¬¸ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    # ì‹œë„ëª… ì»¬ëŸ¼ì´ ìˆê³ , ìœ íš¨í•œ ê°’ì´ ìˆì„ ë•Œë§Œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    if 'ì‹œë„ëª…' in transport_df.columns and transport_df['ì‹œë„ëª…'].notna().any(): 
        fig1, ax1 = plt.subplots(figsize=(10, 5))
        # 'ì‹œë„ëª…' ì»¬ëŸ¼ìœ¼ë¡œ ê·¸ë£¹í™”
        transport_df.groupby('ì‹œë„ëª…').size().sort_values(ascending=False).plot(kind='barh', ax=ax1, color='skyblue') # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        ax1.set_title("ì‹œë„ë³„ ì´ì†¡ ê±´ìˆ˜")
        ax1.set_xlabel("ê±´ìˆ˜")
        ax1.set_ylabel("ì‹œë„")
        plt.tight_layout() # ë ˆì´ì•„ì›ƒ ìë™ ì¡°ì •
        st.pyplot(fig1)
    else:
        st.warning("ì´ì†¡ ë°ì´í„°ì— 'ì‹œë„ëª…' ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ìœ íš¨í•œ ì‹œë„ëª… ê°’ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.warning("ì´ì†¡ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œì™€ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# -------------------------------
# 2ï¸âƒ£ ì‹œê°„ëŒ€ë³„ ë¶„ì„
# -------------------------------
st.subheader("2ï¸âƒ£ ì‹œê°„ëŒ€ë³„ ì‘ê¸‰ì‹¤ ì´ìš© í˜„í™© (2023)")
if not time_df.empty and region:
    # time_dfì—ì„œ í•´ë‹¹ ì§€ì—­ì˜ ë°ì´í„° í–‰ ì„ íƒ
    time_row = time_df[time_df['ì‹œë„'] == region].iloc[0, 1:]
    
    fig2, ax2 = plt.subplots()
    time_row.plot(kind='bar', color='deepskyblue', ax=ax2)
    ax2.set_ylabel("ì´ìš© ê±´ìˆ˜")
    ax2.set_xlabel("ì‹œê°„ëŒ€")
    ax2.set_title(f"{region} ì‹œê°„ëŒ€ë³„ ì‘ê¸‰ì‹¤ ì´ìš©")
    st.pyplot(fig2)
else:
    st.warning("ì‹œê°„ëŒ€ë³„ ë°ì´í„° ë¡œë“œì— ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§€ì—­ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# -------------------------------
# 3ï¸âƒ£ ì›”ë³„ ë¶„ì„
# -------------------------------
st.subheader("3ï¸âƒ£ ì›”ë³„ ì‘ê¸‰ì‹¤ ì´ìš© í˜„í™© (2023)")
if not month_df.empty and region:
    # month_dfì—ì„œ í•´ë‹¹ ì§€ì—­ì˜ ë°ì´í„° í–‰ ì„ íƒ
    month_row = month_df[month_df['ì‹œë„'] == region].iloc[0, 1:]
    
    fig3, ax3 = plt.subplots()
    month_row.plot(kind='line', marker='o', color='seagreen', ax=ax3)
    ax3.set_ylabel("ì´ìš© ê±´ìˆ˜")
    ax3.set_xlabel("ì›”")
    ax3.set_title(f"{region} ì›”ë³„ ì‘ê¸‰ì‹¤ ì´ìš©")
    st.pyplot(fig3)
else:
    st.warning("ì›”ë³„ ë°ì´í„° ë¡œë“œì— ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§€ì—­ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# -------------------------------
# 4ï¸âƒ£ ìš°ì„ ìˆœìœ„ í ì‹œë®¬ë ˆì´ì…˜
# -------------------------------
st.subheader("4ï¸âƒ£ ì‘ê¸‰ ëŒ€ê¸° ì‹œë®¬ë ˆì´ì…˜ (ìŠ¤íƒ/í ëª¨ë¸)")
mode = st.radio("ëŒ€ê¸° ë°©ì‹ ì„ íƒ", ['í (ì„ ì…ì„ ì¶œ)', 'ìŠ¤íƒ (í›„ì…ì„ ì¶œ)'])
patient_input = st.text_input("í™˜ì ì´ë¦„ (ì‰¼í‘œë¡œ êµ¬ë¶„)", "í™ê¸¸ë™,ê¹€ì˜í¬,ì´ì² ìˆ˜")
patients = [p.strip() for p in patient_input.split(',') if p.strip()]

if patients:
    st.write("**ì§„ë£Œ ìˆœì„œ:**")
    if mode == 'í (ì„ ì…ì„ ì¶œ)':
        queue = deque(patients)
        st.write(list(queue))
    else:
        st.write(list(reversed(patients)))

st.markdown("---")
st.caption("â“’ 2025 ìŠ¤ë§ˆíŠ¸ ì‘ê¸‰ì˜ë£Œ ë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸ - SDG 3.8 ë³´ê±´ì„œë¹„ìŠ¤ ì ‘ê·¼ì„± ê°œì„ ")
